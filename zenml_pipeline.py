from zenml import pipeline, step
import subprocess
import argparse
import os
import sys

@step
def prepare_data(source_dir: str):
    print(f"âœ… [prepare_data] æ•°æ®å‡†å¤‡é˜¶æ®µï¼Œæºç›®å½•: {source_dir}")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ process.py
    process_file = os.path.join(source_dir, "process.py")
    if os.path.exists(process_file):
        print("ğŸ” å‘ç° process.pyï¼Œè°ƒç”¨è‡ªå®šä¹‰æ•°æ®å¤„ç†å‡½æ•°")
        try:
            # åŠ¨æ€å¯¼å…¥ process.py
            sys.path.insert(0, source_dir)
            import process
            
            # è°ƒç”¨ process_data å‡½æ•°
            result = process.process_data(source_dir)
            if isinstance(result, tuple) and len(result) == 2:
                dataset_dir, dataset_eval_dir = result
                print(f"ğŸ“ è®­ç»ƒæ•°æ®ç›®å½•: {dataset_dir}")
                print(f"ğŸ“ è¯„ä¼°æ•°æ®ç›®å½•: {dataset_eval_dir}")
                return dataset_dir, dataset_eval_dir
            else:
                raise ValueError("process_data å‡½æ•°å¿…é¡»è¿”å›åŒ…å«ä¸¤ä¸ªå…ƒç´ çš„å…ƒç»„")
        except Exception as e:
            print(f"âŒ è°ƒç”¨ process.py å¤±è´¥: {e}")
            raise
        finally:
            # æ¸…ç† sys.path
            if source_dir in sys.path:
                sys.path.remove(source_dir)
    else:
        print("ğŸ“‚ æœªå‘ç° process.pyï¼Œä½¿ç”¨é»˜è®¤ç›®å½•ç»“æ„")
        # é»˜è®¤ä½¿ç”¨ source_dir/train å’Œ source_dir/eval
        dataset_dir = os.path.join(source_dir, "train")
        dataset_eval_dir = os.path.join(source_dir, "eval")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(dataset_dir):
            print(f"âš ï¸  è­¦å‘Š: è®­ç»ƒæ•°æ®ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        if not os.path.exists(dataset_eval_dir):
            print(f"âš ï¸  è­¦å‘Š: è¯„ä¼°æ•°æ®ç›®å½•ä¸å­˜åœ¨: {dataset_eval_dir}")
            
        print(f"ğŸ“ è®­ç»ƒæ•°æ®ç›®å½•: {dataset_dir}")
        print(f"ğŸ“ è¯„ä¼°æ•°æ®ç›®å½•: {dataset_eval_dir}")
        return dataset_dir, dataset_eval_dir

@step
def train_model(dataset_dirs: tuple, training_script: str, training_env: str = None):
    dataset_dir, dataset_eval_dir = dataset_dirs
    print(f"ğŸš€ [train_model] è®­ç»ƒæ•°æ®ç›®å½•: {dataset_dir}")
    print(f"ğŸš€ [train_model] è¯„ä¼°æ•°æ®ç›®å½•: {dataset_eval_dir}")
    print(f"ğŸš€ [train_model] è®­ç»ƒè„šæœ¬: {training_script}")
    
    # å‡†å¤‡ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ç½®
    if "DATASET_DIR" not in env:
        env["DATASET_DIR"] = dataset_dir
        print(f"ğŸ”§ è®¾ç½®ç¯å¢ƒå˜é‡ DATASET_DIR: {dataset_dir}")
    else:
        print(f"ğŸ”§ ä½¿ç”¨ç°æœ‰ç¯å¢ƒå˜é‡ DATASET_DIR: {env['DATASET_DIR']}")
        
    if "DATASET_EVAL_DIR" not in env:
        env["DATASET_EVAL_DIR"] = dataset_eval_dir
        print(f"ğŸ”§ è®¾ç½®ç¯å¢ƒå˜é‡ DATASET_EVAL_DIR: {dataset_eval_dir}")
    else:
        print(f"ğŸ”§ ä½¿ç”¨ç°æœ‰ç¯å¢ƒå˜é‡ DATASET_EVAL_DIR: {env['DATASET_EVAL_DIR']}")
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    if training_env:
        print(f"ğŸ”§ ä½¿ç”¨è®­ç»ƒç¯å¢ƒ: {training_env}")
        # å¦‚æœæŒ‡å®šäº† training_envï¼Œä¼ é€’ --training_env å‚æ•°ç»™è®­ç»ƒè„šæœ¬
        cmd = ["bash", training_script, "--training_env", training_env]
    else:
        cmd = ["bash", training_script]
    
    print(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=True, text=True, env=env)
    
    print("ğŸ“‹ è®­ç»ƒè¾“å‡º:")
    print(result.stdout)
    if result.returncode != 0:
        print("âŒ è®­ç»ƒé”™è¯¯:")
        print(result.stderr)
        raise RuntimeError("è®­ç»ƒå¤±è´¥")
    
    # å‡è®¾è®­ç»ƒè„šæœ¬è¾“å‡º output_dir åˆ° stdout çš„æœ€åä¸€è¡Œï¼Œæˆ–è€…ä½¿ç”¨é»˜è®¤è·¯å¾„
    output_lines = result.stdout.strip().split('\n')
    if output_lines and output_lines[-1].strip():
        # å°è¯•ä»æœ€åä¸€è¡Œè·å–è¾“å‡ºç›®å½•
        potential_output = output_lines[-1].strip()
        if os.path.exists(potential_output):
            output_dir = potential_output
        else:
            # ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•
            output_dir = os.path.join(os.getcwd(), "output")
    else:
        # ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•
        output_dir = os.path.join(os.getcwd(), "output")
    
    print(f"ğŸ“ è®­ç»ƒè¾“å‡ºç›®å½•: {output_dir}")
    return output_dir

@step
def evaluate_model(output_dir: str):
    print(f"ğŸ§© [evaluate_model] æ¨¡å‹è¾“å‡ºç›®å½•: {output_dir}")
    print("ğŸ“Š æ¨¡å‹è¯„ä¼°é˜¶æ®µï¼ˆå¾…å®ç°ï¼‰")
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(output_dir):
        print(f"âš ï¸  è­¦å‘Š: è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
        return "evaluation_failed"
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„è¯„ä¼°é€»è¾‘
    # ä¾‹å¦‚ï¼šåŠ è½½æ¨¡å‹ã€è¿è¡Œè¯„ä¼°è„šæœ¬ç­‰
    print(f"ğŸ“ è¯„ä¼°æ¨¡å‹ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
    
    return "evaluation_done"

@pipeline(enable_cache=False)
def training_pipeline(source_dir: str, training_script: str, training_env: str = None):
    dataset_dirs = prepare_data(source_dir)
    output_dir = train_model(dataset_dirs, training_script, training_env)
    evaluate_model(output_dir)

if __name__ == "__main__":
    print("ğŸŒ€ å¯åŠ¨ ZenML Pipeline ...")
    parser = argparse.ArgumentParser(description="ZenML è®­ç»ƒç®¡é“")
    parser.add_argument("--source_dir", type=str, required=True, 
                       help="æ•°æ®æºç›®å½•è·¯å¾„")
    parser.add_argument("--training_script", type=str, default="run_training.sh",
                       help="è®­ç»ƒè„šæœ¬è·¯å¾„ (é»˜è®¤: run_training.sh)")
    parser.add_argument("--training_env", type=str, default=None,
                       help="è®­ç»ƒç¯å¢ƒè„šæœ¬è·¯å¾„ (å¯é€‰)")
    args = parser.parse_args()
    
    print(f"ğŸ“‚ æ•°æ®æºç›®å½•: {args.source_dir}")
    print(f"ğŸš€ è®­ç»ƒè„šæœ¬: {args.training_script}")
    if args.training_env:
        print(f"ğŸ”§ è®­ç»ƒç¯å¢ƒ: {args.training_env}")
    
    training_pipeline(args.source_dir, args.training_script, args.training_env)
